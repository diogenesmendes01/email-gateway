groups:
  - name: email_gateway_alerts
    interval: 30s
    rules:
      # High failure rate alert
      - alert: HighEmailFailureRate
        expr: |
          (
            rate(email_failed_total[5m])
            /
            (rate(email_sent_total[5m]) + rate(email_failed_total[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          service: email-gateway
        annotations:
          summary: "Email failure rate > 5%"
          description: "Failure rate: {{ $value | humanizePercentage }} for company {{ $labels.company_id }}"
          action: "Check SES status, database connectivity, and recent deployments"

      # Queue backlog alert
      - alert: QueueBacklog
        expr: email_queue_size{queue="email_queue_waiting"} > 10000
        for: 10m
        labels:
          severity: warning
          service: email-gateway
        annotations:
          summary: "Email queue backlog > 10k"
          description: "Queue size: {{ $value }} emails waiting"
          action: "Scale worker instances or investigate processing bottleneck"

      # Critical queue backlog
      - alert: CriticalQueueBacklog
        expr: email_queue_size{queue="email_queue_waiting"} > 50000
        for: 5m
        labels:
          severity: critical
          service: email-gateway
        annotations:
          summary: "CRITICAL: Email queue backlog > 50k"
          description: "Queue size: {{ $value }} emails waiting"
          action: "IMMEDIATE: Scale workers or investigate system failure"

      # High encryption latency
      - alert: HighEncryptionLatency
        expr: histogram_quantile(0.95, rate(encryption_duration_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
          service: email-gateway
        annotations:
          summary: "Encryption p95 latency > 500ms"
          description: "95th percentile latency: {{ $value | humanizeDuration }}"
          action: "Check CPU usage, review encryption key rotation"

      # API high latency
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, rate(email_send_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          service: email-gateway
        annotations:
          summary: "API p95 latency > 2s"
          description: "95th percentile latency: {{ $value | humanizeDuration }}"
          action: "Check database, Redis, and queue performance"

      # No metrics from API
      - alert: APIDown
        expr: up{job="email-gateway-api"} == 0
        for: 2m
        labels:
          severity: critical
          service: email-gateway
        annotations:
          summary: "Email Gateway API is down"
          description: "API has been down for more than 2 minutes"
          action: "IMMEDIATE: Check API container/process status"

      # No metrics from Worker
      - alert: WorkerDown
        expr: up{job="email-gateway-worker"} == 0
        for: 2m
        labels:
          severity: critical
          service: email-gateway
        annotations:
          summary: "Email Gateway Worker is down"
          description: "Worker has been down for more than 2 minutes"
          action: "IMMEDIATE: Check Worker container/process status"

      # High retry rate
      - alert: HighRetryRate
        expr: |
          (
            sum(rate(email_retry_total[5m]))
            /
            sum(rate(email_sent_total[5m]))
          ) > 0.2
        for: 10m
        labels:
          severity: warning
          service: email-gateway
        annotations:
          summary: "Email retry rate > 20%"
          description: "Retry rate: {{ $value | humanizePercentage }}"
          action: "Check SES rate limits, network connectivity"

      # Active queue jobs stuck
      - alert: ActiveJobsStuck
        expr: email_queue_size{queue="email_queue_active"} > 100
        for: 15m
        labels:
          severity: warning
          service: email-gateway
        annotations:
          summary: "Active queue jobs > 100 for 15+ minutes"
          description: "Active jobs: {{ $value }}"
          action: "Check for worker deadlocks or stuck jobs"
